{
  "bindrep": {
    "rc": 1,
    "out": "usage:\nasc_bindrep [options] [tosca-env/stage] [dbname]\n  options: -v version (default v210)\n           -g         (for Customers: also check GGRL-Stored-Procedures - in ccc always checked )\n           -f         force bind\n           -s         only check stored procedures\n           -t         activate Trace\n--------------------------------------------------------------------------------------\nperforms db2 bind for databases assigned in asc_bind_azp.conf or ttosca_bind\nexample:\nasc_bindrep f         - bind databases assigned to V210_FACHTEST_DB\nasc_bindrep -v v155 p - bind databases assigned to V155_PROD_DB\nasc_bindrep i DTCOR01 - bind DTCOR01 if assigned to V210_INTTEST_DB\nasc_bindrep extv3      - bind all TOSCSA-extv3-assigned databases\nasc_bindrep -s -v v240 - check all stored-procedures for databases assigned to V240\n--------------------------------------------------------------------------------------\n"
  },
  "xesim": {
    "rc": 1,
    "out": "resolves input jcl and shows it in xe\n usage:\n   xesim  <input-jcl> [ <odate> ]\n   eg.\n   xesim /home/varresolve/VOTOVG.jcl\n   xesim /home/varresolve/VOTOVG.jcl 160523\n"
  },
  "uedit": {
    "rc": 0,
    "out": "options:\n-h, --help              show brief help\n-i, --ip                fuer host aufruf mit ip \nParm 1:  dataset\nexamples dataset: for MF-DATASETS\n1) /shared/data/COR/COR0.BATE.UEBERW.ENDREF.DAT     Nur 1 FILE\n2) COR0.BATE.UEBERW.ENDREF                          Nur 1 FILE\n3) COR0.B*.UEBERW.ENDREF                            Alle mit B*\n\nexamples dataset: for LX-DATASETS\n1) /shared/ae/userlib/ps99/jcl/              alle in dem Ordner\n2) /shared/ae/userlib/ps99/jcl/TEST+         alle die mit TEST beginnen\n3) /shared/ae/userlib/ps99/jcl/TEST5.jcl     nur TEST5.jcl\n\n"
  },
  "scanError": {
    "rc": 1,
    "out": "usage:\nscanError [options] DSNAME [tracefile]\n options:\n   -e (extended output having additional columns: HLQ, Date, ..)\n   -H (no CSV header record)\n   -S (no progress Status)\n\ne.g:  scanError E1DIZJ.DRFEHL.*.#190502\n      scanError -e E1DIZJ.DRFEHL.*.#190502 > E1_scanError190502_all.csv\n"
  },
  "diffError.sh": {
    "rc": 1,
    "out": "usage:\ndiffError.sh [options] oldfile newfile \n options:\n   -e (show equal errros)\n   -n (show new errors - default)\n   -o (show old errors)\n\ne.g:  diffError E1_scanError190507.csv E1_scanError190508.csv\n"
  },
  "espa": {
    "rc": 0,
    "out": "usage: espa [-h] [-e [ENVIRON]] [-d date-filter] [-qs] [-l [limit]]\n            [-f compl,(c)cput,(d)dura,(i)jobid,(n)jobnm,(m)memkb,(t)odate,(r)retc,(s)scput,(a)start,(o)stop | -t [all(default)|dura|aver|time|tech] | -xct\n            [main if not specified, else submodule of main] | -x {cosmo,fila,kavl}] [-is [INDEX-FIRST-FILTER] | -ii [INDEX-INC-FILTER] | -ie\n            [INDEX-EXC-FILTER]] [-ip] [-so [<index>,a|<index>,d]] [-fi [<index>,<logical_oper>,<filtexpr>]] [-idu] [-iconsize] [-ocs [FILENAME]] [-com]\n            [-p] [-v]\n            qualifiers [databases]\n\npositional arguments:\n  qualifiers            name of program, used for identifying dres files via third qualifier\n                        with comma seperation 2 additional qualifiers after third for filtering files can be specified\n                        example: ubhqobl,hs\n  databases             databases (triple-digit) comma seperated or 'all', multiple dbs are only allowed for -x options cosmo,fila,kavl\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n\n===> environment options:\n  -e [ENVIRON], --environ [ENVIRON]\n                        default for test servers: lowest\n                        possible environments current server: test,test1,test2,test3,test4\n                        can also be specified by p for prod and number for test environment\n\n===> file related options:\n  -d date-filter, --date date-filter\n                        filter criterion for logical date:\n                        daterange with format 'YYMMDD,' (comma!!) -> fromdate to current date \n                        daterange with format 'YYMMDD,YYMMDD'     -> fromdate to todate\n                        everything else -> regex\n  -qs, --qualified-strict\n                        only the qualifiers from the first positional arguments have to exist (except the qualifiers 1,2 and 4 (odate))\n  -l [limit], --limit [limit]\n                        number of parsed/displayed records, default 30(unsorted/unfiltered)/200(sorted/filtered)\n                        with -l0 all files are displayed upto 11111 (for performance reasons)\n                        workaround for displaying everything is option >-d 010101,<\n\n===> main data output options (exclusive):\n  -f compl,((c)cput,(d)dura,(i)jobid,(n)jobnm,(m)memkb,(t)odate,(r)retc,(s)scput,(a)start,(o))stop\n                        parsed fields to be included in output stream, comma seperated or single field:\n                           compl   CompileTS\n                        (c)cput    CPUtm\n                        (d)dura    Duration\n                        (i)jobid   JobID\n                        (n)jobnm   Jobname\n                        (m)memkb   MemKB\n                        (t)odate   Date\n                        (r)retc    Returncode\n                        (s)scput   SCPUtm\n                        (a)start   Start\n                        (o)stop    Stop\n  -t [all((default))|dura|aver|time|tech], --totals-fields [all((default))|dura|aver|time|tech]\n                        print data based on indices of totals fields\n                        number of total fields printed is limited by size of terminal, can be deactivated by option iconsize\n                        indices out of range are ignored\n                           all: print all fields\n                          dura: print duration fields\n                          aver: print performance fields\n                          time: print average for performance fields\n                          tech: print average for performance fields\n  -xct [main if not specified, else submodule of main], --xctmodule [main if not specified, else submodule of main]\n                        check mainmodule or submodule for compiletime changes\n  -x {cosmo,fila,kavl}, --xfeat {cosmo,fila,kavl}\n                        fila:     print first and last filename for each tenant\n                        cosmo:    print comma seperated modules called during execution\n                        kavl:     print first line control statement\n\n===> tablular output related options to be used with option >-t<:\n  -is [INDEX-FIRST-FILTER], --index-start [INDEX-FIRST-FILTER]\n                        is >index<: : print indices starting with\n  -ii [INDEX-INC-FILTER], --index-include [INDEX-INC-FILTER]\n                        ii >indices<: include fields based on indices (comma seperated), eg >-ii 3,6-8,9<\n  -ie [INDEX-EXC-FILTER], --index-exclude [INDEX-EXC-FILTER]\n                        ie >indices<: exclude fields based on indices (comma seperated), eg >-ie 3,6-8,9<\n  -ip, --index-print    print indices/names for filter selection\n  -so [<index>,a|<index>,d], --sortindex [<index>,a|<index>,d]\n                        order counts by index, default index is 1\n                        default ordering ascendig, descending can be specified by appending d\n                        indices out of range are ignored\n                        example: -so     -> sort by index 1\n                        example: -so 3   -> sort by index 3\n                        example: -so d   -> sort by index 1 descending\n                        example: -so 5,d -> sort by index 5 descending\n  -fi [<index>,<logical_oper>,<filtexpr>], --filter-expession [<index>,<logical_oper>,<filtexpr>]\n                        filter expression for numbers or dates located at specific index, \n                        indices out of range are ignored\n                        example date:   -fi 1,eq,2h10m4s45ms\n                        example number: -fi 1,gt,0\n  -idu, --insert-duration\n                        include duration at position one when printing counters, only possible with option t\n  -iconsize, --ignore-consolesize\n                        display all indices independent of console size, useful for writing output to file\n  -ocs [FILENAME], --output-commaseper [FILENAME]\n                        filename for comma separated output\n\n===> other options:\n  -com, --compact       don't print empty lines for grouping, information messages\n  -p, --printlog        print log records\n"
  },
  "dj": {
    "rc": 0,
    "out": "usage: dj [-h] [-v] jobname [action]\n\ndescription: resolve job, browse or edit job\n\npositional arguments:\n  jobname        name of job to be displayed\n  action         action to be taken:\n                 if not specified resolve with current date\n                 date in format YYMMDD for resolving\n                 number of days between 1 and 7 for resolving backward days\n                 b (browse with mfbr)\n                 e (edit with mfed)\n                 v (edit with vi)\n\noptional arguments:\n  -h, --help     show this help message and exit\n  -v, --version  show program's version number and exit\n\nexample of usage:\n+ resolve with current date              dj EPOTL1DS\n+ resolve with specific date             dj EPOTL1DS 210103\n+ browse unresolved job                  dj EPOTL1DS b\n+ edit unresolved job with mfed          dj EPOTL1DS e\n+ edit unresolved job with vi            dj EPOTL1DS v\n"
  },
  "dt": {
    "rc": 0,
    "out": "usage: dt [-h] [-e [ENVIRON]] [-res] [-det] [-v] [searchstring]\n\ndescription: quick way to display tenant information from TENANTS.var\n\npositional arguments:\n  searchstring          >all< to display all tenants, default if not specified\n                        2 digit numeric string for displaying numeric tenant\n                        2 digit aphabetic string for displaying abs tenant\n                        everything else with length ge 3 is arbitrary string\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -e [ENVIRON], --environ [ENVIRON]\n                        environment, either prod or test<env-number>, default test4 on test server\n                        test envs can also be abbreviated by number, eg -etest5 as -e5\n  -res, --reserve       show reserve\n  -det, --details       show details\n  -v, --version         show program's version number and exit\n\nexample of usage:\ndt             display all tenants (default)\ndt all         display all tenants\ndt 1           display numeric tenant\ndt as -det     display additional fields\ndt de -res     display reserve lines\ndt oe          display normalized tenant\ndt spain       display tenant via arbitrary search string\n"
  },
  "xtrans": {
    "rc": 0,
    "out": "[14:08:05] identifying transaction-files on server ...\nusage: xtrans [-h] [-e [ENVIRON]] [-scan] [-both] [-fne [FNAME_EXT]] [-alsep] [-l LIMIT] [-mha | -mga] [-v] searchstrings dates [tenant]\n\ndescription: extract sections from transaction files containing at least one of the search criteria, optionally only do scan\n\npositional arguments:\n  searchstrings         searchstrings to look for, seperated by \",\" or \"#\"\n  dates                 date in format YYMMDD for daily files (test/prod) and YYMM for monthly files (prod)\n  tenant                tenant triple digit, default tenant is mha\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -e [ENVIRON], --environ [ENVIRON]\n                        possible environments current server: test1,test3,test4\n                        can be abbreviated, eg -e4 or -ep\n  -scan                 scan mode, no extraction, only search is done\n  -both                 show compressed files in addition when printing existing files\n  -fne [FNAME_EXT], --filename-extension [FNAME_EXT]\n                        add to filename, if not spedified add timestamp, with ss add searchstring\n  -alsep, --alternate-seperator\n                        alternative seperator \"#\" to use for search criteria, default is \",\"\n  -l LIMIT, --limit LIMIT\n                        number of transactions to be extracted\n  -mha                  specify tenant mha for file display without positional arguments\n  -mga                  specify tenant mha for file display without positional arguments\n  -v, --version         show program's version number and exit\n\nexample of usage:\n=> xtract all transactions containing uuid from DAILY FILE 241109\nxtrans 7572d4e5-9e40-11ef-b241-7a1e11530eb9 241109 mha\n\n=> xtract all transactions containing uuid from daily file 241108 IN TEST\nxtrans 16db25e4-9d75-11ef-9c1f-fe24e6e78f99 241108 mha -e3\n\n=> xtract data from MULTIPLE DAILY FILES with MULTIPLE SEARCH ARGUMENTS\nxtrans 900951b5-9b0b-11ef-90c7-f27ec5e2afac,ae2fb899-9d67-11ef-85c1-967a32033aa5 241104,241105-241107,241108 mga\n\n=> xtract data from MULTIPLE DAYS OF MONTHLY FILE\nxtrans 0b464c38-829c-11ef-8580-f6e0ca4e0b93 2410,2,4-6,10 mga\n"
  },
  "xtrace": {
    "rc": 0,
    "out": "usage: xtrace [-h] [-split] [-fne [FNAME_EXT]] [-l LIMIT] [-keep] [-v] filename searchstrings\n\ndescription: extract sections from trace file containing at least one of the search criteria, gzip decompression is supported\n             sections are identified by a duration line, generated via module VPZIWLZ, containing duration, time in secs, gf# and returncode\n             only tracefiles containing these lines are applicable for the script\n             if an uncompressed file is not found the script looks for the commpressed file and vice versa (#yymmdd - Zyymmdd)\n\npositional arguments:\n  filename              microfocus file name\n  searchstrings         searchstrings comma seperated, case insensitive\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -split                write sections in seperate files\n                        splitted files are deleted before processing, mergefiles not\n  -fne [FNAME_EXT], --filename-extension [FNAME_EXT]\n                        add to filename, if not spedified add searchstring, ignored in split mode\n  -l LIMIT, --limit LIMIT\n                        maximum/default number of parsed sections: 250 in split mode / 1000 for merged output\n  -keep, --keep-files   do not delete old files\n  -v, --version         show program's version number and exit\n\nexample of usage:\nxtrace EDIVZ.DRTRACE.VPZJOWP.#210101 85050d6d-4c80-11eb-a882-005056b26c52\nxtrace EDIVZ.DRTRACE.VPZJOWP.Z201231 85050d6d-4c80-11eb-a882-005056b26c52\nxtrace <mffilename> <searchstring>\nxtrace <mffilename> <searchstring> -split\n"
  },
  "xspool": {
    "rc": 0,
    "out": "usage: xspool [-h] [-search] [-cs] [-keep] [-v] jobnames/searchcrit date\n\npositional arguments:\n  jobnames/searchcrit   search criterium:\n                        jobname or jobnames comma seperated\n                        with option \"search\" arbitrary string\n  date                  date in format YYMMDD for identiying spool backup file\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -search, --search-mode\n                        search mode, do not extract but display found job sections\n  -cs, --case-sensitive\n                        search case sensitive\n  -keep, --keep-files   do not delete old files\n  -v, --version         show program's version number and exit\n"
  },
  "fp": {
    "rc": 0,
    "out": "usage: fp [-h] [-v] [-b [{152,153,167,190,195,210,230}]] [-s [{prod,vorprod,fretest,uattest,fachtest,inttest}]] [-inc] [-unl] [-both] [-comm] [-cs] [-noma]\n          [-fd [ind|mod|raw]] [-ke] [-det] [-cosmo] [-o [cmd|pag]] [-allmix] [-allseq] [-join] [-lit] [-muw] [-pre] [-wor] [-kc] [-nc | -wb]\n          search_crit [module_filter]\n\nsearch in pl1 programs or includes with regular expression for matching statement_buf\nper default comments are ignored and core modules are only searched if a customer specific module does not exist\n\npositional arguments:\n  search_crit           search criterium, for a regex single or double quotes are needed if special characters or blanks are used\n  module_filter         module name filter criteria\n                        either glob pattern, wildcards *, ? and range ([]) can be used, default is \"*\"\n                        or list of module names comma seperated\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n\ntarget environment arguments:\n  -b [{152,153,167,190,195,210,230}], --branch [{152,153,167,190,195,210,230}]\n                        branch to search for, default is 230\n  -s [{prod,vorprod,fretest,uattest,fachtest,inttest}], --stage [{prod,vorprod,fretest,uattest,fachtest,inttest}]\n                        stage to search for, default is prod\n\nmodule type arguments:\n  -inc, --include-search\n                        search includes\n  -unl, --unload-search\n                        search unloads\n\nsearch related arguments:\n  -both, --search-both  search also core modules if customer specific exists, default: no search\n  -comm, --search-comments\n                        search also comments\n  -cs, --case-sensitive\n                        search case sensitive\n  -noma, --no-match     print files without any match (option details ignored)\n\noutput related arguments:\n  -fd [ind|mod|raw], --flag-details [ind|mod|raw]\n                        markers for statements: ind: indented\n                                                mod: modulename (default)\n                                                raw: no marker\n  -ke, --keep-empty     keep empty statement lines\n  -det, --show-details  show found statement_buf\n  -cosmo, --comma-seper-modules\n                        display only modulenames, commaseperated\n  -o [cmd|pag], --output-stream [cmd|pag]\n                        output streams: cmd: command line window\n                                        pag: pager (default)\n\nregex helper arguments:\n  -allmix, --allwords-mixed\n                        search for all words with no sequential order,\n                        combinations will be built for all words except those marked as anchors with >#<\n  -allseq, --allwords-sequential\n                        search for all words in sequential order\n  -join, --table-join   search for joined table names ,names should start with dot to match T- and V-tables\n  -lit, --literally     search as literal, not regex\n  -muw, --multiple-whitespace\n                        search literal blanks as multiple whitespace\n  -pre, --preconfigured\n                        search preconfigured regeces, available values: desc,vlk\n  -wor, --word-variants\n                        search for words, word seperator is blank\n\ncolor arguments:\n  -kc, --keep-colorcode\n                        force coloring also for redirection or pipes, \n                        usable with less pager, eg >fp searchcrit -det -kc | less -r<\n  -nc, --no-color       do not color output\n  -wb, --white-background\n                        coloring for white background\n                        this can also be achieved by creating the file >/home/a9635/fp_white_background<\n\n--> usage examples:\n+ specific environment                                                fp .mo1_lberperssach -b 210 -s vorprod\n+ find all includes related to beneficiary table, also in comments    fp lberperssach -inc -comm\n+ find in claims modules case sensitive                               fp KZTEST sch -cs\n+ find all insert statement_buf for thbschnitsstelle                  fp \"insert\\s+into\\s+.hbschnittstelle\"\n+ find call_ctr on ubhqmsa with detailed statement_buf                fp \"call\\s+ubhqmsa\" -det\n+ find domain value in finance modules                                fp 'slana' ubh\n+ print all pligen modules to use result as a module-filter           fp pligen -comm -cosmo\n\n--> helper options:\n+ literal blanks to multiple whitespace           fp \"update .vertrag set\" -muw          > translated to \"update\\s+.vertrag\\s+set\"\n+ find literally                                  fp \"....\" -lit                         > translated to \"\\.\\.\\.\\.\"\n+ find word                                       fp mo1_lberperssach -wor               > translated to \"\\bmo1_lberperssach\\b\"\n+ find table joins                                fp '.vertrag .person' -join\n"
  },
  "my_release_changes": {
    "rc": 0,
    "out": "usage: my_release_changes [-h] [-v] [release]\n\ncheck own release changes not yet in production\n\npositional arguments:\n  release        release to be checked, eg 23.A or 23.A.1\n\noptional arguments:\n  -h, --help     show this help message and exit\n  -v, --version  show program's version number and exit\n"
  },
  "cfm": {
    "rc": 0,
    "out": "usage: cfm [-h] [-trail] [-v] mffile\n\ndescription: copy file from mfds to predefined folder <home>/_copied_from_mfds>\n\npositional arguments:\n  mffile         micorfocus file name to be copied\n\noptional arguments:\n  -h, --help     show this help message and exit\n  -trail         preserve trailing blanks when copying\n  -v, --version  show program's version number and exit\n"
  },
  "taildrst": {
    "rc": 0,
    "out": "\ntaildrst is a bash script to monitor DRST files for PL/I programs/tasks\nPress CTRL-C to terminate trace.\n\nUsage: taildrst <fully_qualified_path_to_*DRST.DAT_file>\ni.e.: taildrst /shared/awp/prod/spool/MHAN/Y2021.S0318.S010126.J0089519.D00006.DRST.DAT\n\n"
  }
}